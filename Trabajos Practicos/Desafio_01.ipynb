{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c1ed8c",
   "metadata": {},
   "source": [
    "# Consigna del desafío 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e791b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
    "# en sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fab520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar datos\n",
    "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133e8cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once again, it appears that the one-eyed man has appeared in the land of the sighted\n",
      "and for some strange resaon has appointed himself the ruler and supreme power.\n"
     ]
    }
   ],
   "source": [
    "# en el atributo `data` accedemos al texto\n",
    "print(train.data[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b7bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The front covers should be available from Sony.  Check with a local car\n",
      "stereo shop.  You will probably (definitely) have to provide the units \n",
      "serial number and hopefully you had registered the warranty card.  I \n",
      "don't know the cost, but replacements have to be available to people\n",
      "who damage the face cover, so it stands to reason that it can be replaced.\n",
      "\n",
      "As to deterring theft:\n",
      "\n",
      "When I worked for a stereo shop, we referred the customer to a Sony 800\n",
      "number.  We would not sell the face, nor did we have them available.  Most\n",
      "people who came in asking for the face cover (or a pullout sleave for that\n",
      "matter) would look very disheartened to find that they acquired a deck\n",
      "they couldn't use.  If theft occurs with these decks, notify Sony.  Serial\n",
      "numbers do catch theives.\n"
     ]
    }
   ],
   "source": [
    "# en el atributo `data` accedemos al texto\n",
    "print(train.data[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d5da5",
   "metadata": {},
   "source": [
    "## 1. Vectorizar documentos. \n",
    "Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49752e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vectorización\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             ngram_range=(1, 2), \n",
    "                             max_df=0.95, \n",
    "                             min_df=2)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.data)\n",
    "X_test = vectorizer.transform(test.data)\n",
    "y_train = train.target\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1ae3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8e10c",
   "metadata": {},
   "source": [
    "# Estrategia de Resolucion \n",
    "El siguiente codigo realiza:\n",
    "- Se seleccionan 5 documentos aleatoriamente del conjunto de entrenamiento para analizar.\n",
    "- Para cada documento seleccionado, se calcula la similitud del coseno con todos los documentos del corpus.\n",
    "- Se ordenan los documentos según su similitud y se seleccionan los 5 más similares (excluyendo el propio documento).\n",
    "- Se imprimen las clases (temas) de los documentos más similares, para evaluar si tiene sentido semántico la similitud encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7196b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de documentos similares:\n",
      "\n",
      "Documento base (clase: rec.sport.hockey):\n",
      " - Similar a doc 8985 (clase: rec.sport.baseball)\n",
      " - Similar a doc 5064 (clase: rec.sport.hockey)\n",
      " - Similar a doc 3769 (clase: rec.sport.baseball)\n",
      " - Similar a doc 1833 (clase: rec.sport.baseball)\n",
      " - Similar a doc 5640 (clase: sci.crypt)\n",
      "\n",
      "Documento base (clase: comp.sys.mac.hardware):\n",
      " - Similar a doc 9921 (clase: comp.sys.mac.hardware)\n",
      " - Similar a doc 5509 (clase: comp.sys.mac.hardware)\n",
      " - Similar a doc 6364 (clase: comp.sys.mac.hardware)\n",
      " - Similar a doc 6772 (clase: comp.sys.mac.hardware)\n",
      " - Similar a doc 4359 (clase: comp.sys.mac.hardware)\n",
      "\n",
      "Documento base (clase: comp.graphics):\n",
      " - Similar a doc 3444 (clase: comp.graphics)\n",
      " - Similar a doc 1764 (clase: comp.graphics)\n",
      " - Similar a doc 5905 (clase: comp.graphics)\n",
      " - Similar a doc 6117 (clase: comp.windows.x)\n",
      " - Similar a doc 5799 (clase: comp.graphics)\n",
      "\n",
      "Documento base (clase: rec.autos):\n",
      " - Similar a doc 4211 (clase: rec.motorcycles)\n",
      " - Similar a doc 2971 (clase: rec.autos)\n",
      " - Similar a doc 9491 (clase: rec.autos)\n",
      " - Similar a doc 3386 (clase: rec.autos)\n",
      " - Similar a doc 11228 (clase: comp.os.ms-windows.misc)\n",
      "\n",
      "Documento base (clase: rec.sport.hockey):\n",
      " - Similar a doc 10644 (clase: rec.sport.hockey)\n",
      " - Similar a doc 8096 (clase: rec.sport.hockey)\n",
      " - Similar a doc 7478 (clase: rec.sport.hockey)\n",
      " - Similar a doc 7308 (clase: rec.sport.hockey)\n",
      " - Similar a doc 1523 (clase: rec.sport.hockey)\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random_docs = random.sample(range(X_train.shape[0]), 5)\n",
    "print(\"Análisis de documentos similares:\")\n",
    "for doc_idx in random_docs:\n",
    "    sim = cosine_similarity(X_train[doc_idx], X_train).flatten()\n",
    "    top_indices = sim.argsort()[::-1][1:6]\n",
    "    print(f\"\\nDocumento base (clase: {train.target_names[y_train[doc_idx]]}):\")\n",
    "    for i in top_indices:\n",
    "        print(f\" - Similar a doc {i} (clase: {train.target_names[y_train[i]]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e94420",
   "metadata": {},
   "source": [
    "## 2. Entrenar modelos de clasificación Naïve Bayes.\n",
    "Para maximizar el desempeño de clasificación usar (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9df715",
   "metadata": {},
   "source": [
    "## Estrategia de resolucion:\n",
    "El siguiente codigo realiza:\n",
    "- Se definen los dos modelos a comparar: MultinomialNB y ComplementNB.\n",
    "- Para cada modelo se iteran el entrenamiento, prediccion y calculo del score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1d1ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB → Macro F1-score: 0.6504\n",
      "ComplementNB → Macro F1-score: 0.7037\n"
     ]
    }
   ],
   "source": [
    "# 4. Modelos Naive Bayes\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"ComplementNB\": ComplementNB()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    score = f1_score(y_test, preds, average='macro')\n",
    "    print(f\"{name} → Macro F1-score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fcd4f",
   "metadata": {},
   "source": [
    "Ambos modelos logran resultados decentes, pero ComplementNB supera claramente a MultinomialNB.\n",
    "\n",
    "La mejora (~0.05) refleja que la estrategia de usar información de clases complementarias ayuda a generalizar mejor, especialmente en datasets con alta variedad temática y desbalance como 20 Newsgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103cda1",
   "metadata": {},
   "source": [
    "## 3. Transponer la matriz documento-término. \n",
    "De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras. Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed54e3c",
   "metadata": {},
   "source": [
    "Objetivo\n",
    "Evaluar qué palabras del corpus son semánticamente similares en función del contexto en que aparecen. Esto se logra mediante:\n",
    "\n",
    "Representar cada palabra como un vector (basado en los documentos donde aparece).\n",
    "\n",
    "Calcular la similaridad del coseno entre esos vectores.\n",
    "\n",
    "Este enfoque se basa en la idea del espacio vectorial de términos, donde dos palabras son similares si aparecen en contextos similares (principio de distribución semántica de Firth: \"You shall know a word by the company it keeps.\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37df8ca",
   "metadata": {},
   "source": [
    "### Estrategia de resolucion\n",
    "- Obtener el diccionario inverso: idx2word.\n",
    "-  Transponer la matriz documento-término. La matriz X_train tiene forma (n_docs, n_terms) → cada fila es un documento. Al transponerla, obtenemos (n_terms, n_docs) → cada fila ahora representa una palabra como un vector en el espacio de documentos.\n",
    "-  Calcular la matriz de similaridad entre términos. Se calcula la similaridad del coseno entre todos los vectores de palabras. El resultado es una matriz simétrica de forma (n_terms, n_terms), donde: term_sim[i, j] es la similaridad entre la palabra i y la palabra j.\n",
    "-  Definir palabras relevantes. Se seleccionan manualmente 5 palabras de interés, evitando términos poco interpretables o muy raros. Esto es importante para poder analizar semánticamente los resultados.\n",
    "-  Buscar palabras similares para cada palabra objetivo. Para cada palabra:\n",
    "   -  Se obtiene su índice.\n",
    "   -  Se accede a su fila de similaridades term_sim[idx].\n",
    "   -  Se ordenan los índices de términos por mayor similaridad (argsort()[::-1]) y se toman los 5 más similares (excluyendo el propio término si fuera necesario).\n",
    "   -  Se imprime la lista de términos más cercanos semánticamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698a9f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras más similares:\n",
      "'jesus' → ['jesus said', 'jesus christ', 'christ', 'jesus did', 'god']\n",
      "'car' → ['car car', 'new car', 'bought car', 'car dealer', 'buying car']\n",
      "'windows' → ['ms windows', 'dos', 'windows nt', 'dos windows', 'windows windows']\n",
      "'science' → ['collection competing', 'religious sects', 'like science', 'psychology like', 'competing religious']\n",
      "'game' → ['game game', 'game espn', 'games', 'wings game', 'game want']\n"
     ]
    }
   ],
   "source": [
    "idx2word = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "X_term_doc = X_train.T\n",
    "term_sim = cosine_similarity(X_term_doc)\n",
    "words = ['jesus', 'car', 'windows', 'science', 'game']\n",
    "print(\"\\nPalabras más similares:\")\n",
    "for word in words:\n",
    "    idx = vectorizer.vocabulary_.get(word)\n",
    "    if idx:\n",
    "        sim_words = term_sim[idx].argsort()[::-1][1:6]\n",
    "        print(f\"'{word}' → {[idx2word[i] for i in sim_words]}\")\n",
    "    else:\n",
    "        print(f\"'{word}' no está en el vocabulario.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap_profundo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
